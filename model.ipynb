{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UccdDeuUzkFR"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4onExGLmzl_M",
    "outputId": "4f6f4eb9-54e1-43c5-c672-0775ee3354c5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'psycopg2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_272732\\237365854.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Read the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdb_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"postgresql://root:Open4039!@finalpostgresdb.cxwdymdhaxq6.us-east-1.rds.amazonaws.com:5432/my_final_project\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdb_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql_table\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m'a_z_handwritten_data'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36mcreate_engine\u001b[1;34m(url, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\sqlalchemy\\util\\deprecations.py\u001b[0m in \u001b[0;36mwarned\u001b[1;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    307\u001b[0m                         \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m                     )\n\u001b[1;32m--> 309\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\sqlalchemy\\engine\\create.py\u001b[0m in \u001b[0;36mcreate_engine\u001b[1;34m(url, **kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m                 \u001b[0mdbapi_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpop_kwarg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[0mdbapi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdialect_cls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdbapi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdbapi_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[0mdialect_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dbapi\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdbapi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\psycopg2.py\u001b[0m in \u001b[0;36mdbapi\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    780\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdbapi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 782\u001b[1;33m         \u001b[1;32mimport\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    783\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'psycopg2'"
     ]
    }
   ],
   "source": [
    "# # Read the dataset\n",
    "# # Read the data as data type float32 as the csv file is very large\n",
    "\n",
    "# data = pd.read_csv(\"A_Z Handwritten Data.csv\").astype(\"float32\")\n",
    "# data.head(10)\n",
    "# Read the \n",
    "db_string = f\"postgresql://root:Open4039!@finalpostgresdb.cxwdymdhaxq6.us-east-1.rds.amazonaws.com:5432/my_final_project\"\n",
    "engine = create_engine(db_string)\n",
    "\n",
    "data = pd.read_sql_table( 'a_z_handwritten_data' , con = engine)\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5T1ihkZTzpGW"
   },
   "outputs": [],
   "source": [
    "# split the data into X and y\n",
    "# X will contain a character image and y will contain a label of that image\n",
    "\n",
    "X = data.drop(\"0\", axis= 1)\n",
    "y = data[\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fu_KB7DRzrl8"
   },
   "outputs": [],
   "source": [
    "# Perform train_test_split on X and y, to get training (x_train, y_train) and testing (x_test, y_test) data.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JpAn24hYzvHM"
   },
   "outputs": [],
   "source": [
    "# Reshape the training and testing image data using numpy to display it inthe form of image.\n",
    "# Context: In the csv file images are present in 784 columns of pixel data We need to convert them to 28 x 28 pixels.\n",
    "\n",
    "x_train = np.reshape(x_train.values, (x_train.shape[0], 28, 28))\n",
    "x_test = np.reshape(x_test.values, (x_test.shape[0], 28, 28))\n",
    "\n",
    "print(\"Training data shape:\", x_train.shape)\n",
    "print(\"Testing data shape: \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AaD9c7A6zv8G"
   },
   "outputs": [],
   "source": [
    "# shuffle the training data so that we can see training on shuffled characters\n",
    "\n",
    "shuffled_data = shuffle(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6dhRZJ59zy15"
   },
   "outputs": [],
   "source": [
    "# Visualize training data, check if conversion to image form worked.\n",
    "import cv2\n",
    "fig, axes = plt.subplots(3,3, figsize = (10,10))\n",
    "axes = axes.flatten()\n",
    "for i in range(9):\n",
    "    _, shu = cv2.threshold(shuffled_data[i], 30, 200, cv2.THRESH_BINARY)\n",
    "    axes[i].imshow(np.reshape(shuffled_data[i], (28,28)), cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZrYtyDk4z0pD"
   },
   "outputs": [],
   "source": [
    "# Reshape data to train the model\n",
    "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2],1)\n",
    "print(\"New shape of training data: \", x_train.shape)\n",
    "print(\"New shape of testing data: \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVx8rsHpz4Ar"
   },
   "outputs": [],
   "source": [
    "# convert float values to categorical values\n",
    "import tensorflow\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_training = to_categorical(y_train, num_classes = 26, dtype='int')\n",
    "y_testing = to_categorical(y_test, num_classes = 26, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XxpPxGhh0BqL"
   },
   "outputs": [],
   "source": [
    "# Import dependencies to create a Convolutional Neural Networks (CNN) model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8YyNLVCe0GKy"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    " \n",
    "model.add(Conv2D(64 , (3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPool2D(2, 2))\n",
    " \n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(2, 2))\n",
    " \n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(2,2))\n",
    " \n",
    "model.add(Flatten())\n",
    " \n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "model.add(Dense(256,activation =\"relu\"))\n",
    "model.add(Dense(26,activation =\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DoiXmlwj0JHR"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWd6Vzql0Vm6"
   },
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer = Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_training, epochs=5,  validation_data = (x_test,y_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7h350Y3_0cTu"
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save(r'character_recog_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nBEp2Lg00f-1"
   },
   "outputs": [],
   "source": [
    "# Create a words dictionary\n",
    "words = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P',16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X',24:'Y',25:'Z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFB0UihT3IWI"
   },
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "fig, axes = plt.subplots(3,3, figsize=(8,9))\n",
    "axes = axes.flatten()\n",
    "for i,ax in enumerate(axes):\n",
    "    image = np.reshape(x_test[i], (28,28))\n",
    "    ax.imshow(image, cmap=\"Greys\")\n",
    "    pred = words[np.argmax(y_testing[i])]\n",
    "    ax.set_title(\"Prediction: \"+pred)\n",
    "    ax.grid()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled12.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
